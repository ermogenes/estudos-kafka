# Integra√ß√£o de bases de dados relacionais com Kafka Connect JDBC

Neste artigo introduziremos os conceitos iniciais para a utiliza√ß√£o de [Apache Kafka](https://kafka.apache.org/) com [Kafka Connect](https://docs.confluent.io/platform/current/connect/index.html) na integra√ß√£o de bancos de dados relacionais.

## Kafka Connect

O Kafka Connect usa a infraestrutura do Apache Kafka para transportar dados entre diversas fontes distintas, de forma simples.

Os dados s√£o consumidos das origens por _workers_ no cluster do Kafka Connect, que executam _tasks_ do tipo _Source_. Cada _source task_ √© configurada usando chaves/valores, e apontam para uma origem de dados, em um determinado formato, e para um t√≥pico Kafka de destino. Tamb√©m podem realizar pequenas transforma√ß√µes nos dados. Existem diversos conectores do tipo _source_, permitindo que os dados sejam obtidos de praticamente qualquer fonte (criar um novo tamb√©m n√£o √© imposs√≠vel). Por exemplo, usando o [JDBC Source Connector](https://docs.confluent.io/kafka-connect-jdbc/current/index.html) podemos configurar para ler uma base de dados SQL Server (o driver JDBC correto deve estar dispon√≠vel) em uma determinada frequ√™ncia, obter certo conjunto de dados, converter em um esquema [Apache Avro](https://avro.apache.org/), e gravar em um t√≥pico.

Usando o mesmo cluster podemos criar _tasks_ do tipo _sink_, que consumir√£o as altera√ß√µes no t√≥pico e gravar√£o os dados em um destino externo (tamb√©m com diversas tecnologias dispon√≠veis). Por exemplo, podemos ler o t√≥pico do exemplo acima e gravar em um banco de dados MySQL usando o [JDBC Sink Connector](https://docs.confluent.io/kafka-connect-jdbc/current/index.html).

Podemos ter m√∫ltiplos conectores gravando no t√≥pico, inclusive produtores n√£o ligados ao Kafka Connect, desde que respeitem o esquema. Podemos tamb√©m ter v√°rios consumidores do t√≥pico independentes, cada qual gravando em destinos diferentes, inclusive consumidores n√£o ligados ao Kafka Connect.

## O problema

Usar o Kafka Connect para obter e despejar dados utilizando fontes n√£o-ACID √© razoavelmente trivial. Por exemplo, podemos consumir um _stream_ de _tweets_ em JSON e grav√°-lo em ElasticSearch sem grandes planejamentos.

As garantias de integridade dadas pelos bancos de dados relacionais implicam que os dados devem sempre estar de acordo com todas as regras impostas pelo seu esquema, inclu√≠ndo formato dos dados, cardinalidade e chaves prim√°rias (muitas vezes com valores imut√°veis calculados pelo SGBD).

H√° conectores espec√≠ficos para alguns SGBD, como SQL Server e MySQL, que n√£o transportam os dados, e sim o _log_ de altera√ß√µes executados no banco. Essa situa√ß√£o parece excelente para replica√ß√£o, mas n√£o para cen√°rios onde os esquemas n√£o s√£o exatamente iguais entre origens e destino.

Nesse artigo usaremos a estrat√©gia de _polling_ (consultas em intervalos pr√©-determinados) com conector JDBC, que permite sua utiliza√ß√£o com virtualmente todos os bancos de dados relacionais.

Considerando cen√°rios onde os dados da origem j√° pr√©-existam em seu esquema relacional tradicional, decis√µes importantes devem ser tomadas quanto √† maneira de se buscar os dados. Isso √© implementado na configura√ß√£o do _source_, em especial na propriedade `mode`.

## Modos de consulta do JDBC Source

Cada modo difere em ess√™ncia dos demais. A escolha do modo correto √© imprescind√≠vel.

- Modo em massa (`mode=bulk`): a cada consulta traz todos os registros pertinentes.
- Modo incremental (`mode=incrementing`): a cada consulta traz somente os registros em que o valor de uma coluna num√©rica √∫nica estritamente crescente (geralmente um identificador chave-prim√°ria) seja maior do que o maior valor lido na √∫ltima consulta. Esse modo permite detectar inclus√µes.
- Modo data/hora (`mode=timestamp`): a cada consulta traz somente os registros em que o valor de uma coluna data/hora n√£o necessariamente √∫nica mas estritamente crescente (geralmente uma coluna com data de atualiza√ß√£o) seja maior do que o maior valor lido na √∫ltima consulta. Esse modo permite detectar altera√ß√µes.
- Modo composto data/hora e incremental (`mode=timestamp+incrementing`): usa as colunas dos modos incremental e data/hora em conjunto para detectar altera√ß√µes e inclus√µes, trazendo somente registros modificados.

Perceba que n√£o h√° uma maneira trivial de se trazer em uma consulta `SELECT` os registros que foram exclu√≠dos (e muitas vezes n√£o h√° maneira nenhuma). Uma sa√≠da elegante seria tratar as exclus√µes sempre logicamente nas tabelas de origem.

Outro ponto de aten√ß√£o √© a necessidade de cria√ß√£o de √≠ndices envolvendo as colunas indicadas, j√° que ser√£o executadas com frequ√™ncia. Podem ser utilizadas tamb√©m tabelas-espelho ou mesmo _views_. Para cada caso avalie a melhor estrat√©gia pesando desempenho e lat√™ncia.

O intervalo de _poll_ √© essencial tamb√©m. Uma _query_ r√°pida pode permitir _polling_ mais frequente, mas consultas pesadas devem ter sua repeti√ß√£o ajustada para intervalos maiores, ao custo da lat√™ncia aumentada.

### Modo em massa

Traz uma fotografia instant√¢nea de um conjunto de dados.

A cada intervalo de _polling_ uma _query_ `SELECT` √© executada sem a inclus√£o de nenhuma condi√ß√£o `WHERE` pelo conector. Todos os registros retornados s√£o publicados no t√≥pico, independentemente de j√° terem sido consumidos anteriormente.

Exemplo:

Considere os dados na tabela de origem:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
1 | Maria   | Sim | 2020-12-01 16:22:15.170
2 | Ant√¥nio | Sim | 2010-02-14 04:35:04.041
3 | Estela  | Sim | 2021-06-30 12:02:00.406

Considere um conector configurado para ler todas as colunas da tabela, e utilizar a coluna `id` como chave do t√≥pico. Ap√≥s dois intervalos de consulta, o t√≥pico conter√° algo como:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
1 | Maria   | Sim | 2020-12-01 16:22:15.170
2 | Ant√¥nio | Sim | 2010-02-14 04:35:04.041
3 | Estela  | Sim | 2021-06-30 12:02:00.406
1 | Maria   | Sim | 2020-12-01 16:22:15.170
2 | Ant√¥nio | Sim | 2010-02-14 04:35:04.041
3 | Estela  | Sim | 2021-06-30 12:02:00.406

Um consumidor de destino que consuma esse t√≥pico deve saber necessariamente lidar com registros duplicados (por exemplo, fazendo um _upsert_ de acordo com a chave-prim√°ria).

Digamos que o segundo registro tenha sido alterado, o terceiro exclu√≠do e um quarto cadastrado, deixando a tabela assim:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
1 | Maria   | Sim | 2020-12-01 16:22:15.170
2 | Ant√¥nio | N√£o | 2021-06-30 12:10:06.965
4 | Joaquim | Sim | 2018-06-30 12:10:07.152

Na pr√≥xima consulta o t√≥pico conter√°:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
1 | Maria   | Sim | 2020-12-01 16:22:15.170
2 | Ant√¥nio | Sim | 2010-02-14 04:35:04.041
3 | Estela  | Sim | 2021-06-30 12:02:00.406
1 | Maria   | Sim | 2020-12-01 16:22:15.170
2 | Ant√¥nio | Sim | 2010-02-14 04:35:04.041
3 | Estela  | Sim | 2021-06-30 12:02:00.406
1 | Maria   | Sim | 2020-12-01 16:22:15.170
2 | Ant√¥nio | N√£o | 2021-06-30 12:10:06.965
4 | Joaquim | Sim | 2018-06-30 12:10:07.152

Perceba que o valor de `atualizado_em` foi gravado com valor anterior aos demais, sem preju√≠zo da consulta.

Um destino que monitore o t√≥pico, tratando as entradas duplicadas, dever√° ter o seguinte conte√∫do:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
1 | Maria   | Sim | 2020-12-01 16:22:15.170
2 | Ant√¥nio | N√£o | 2021-06-30 12:10:06.965
3 | Estela  | Sim | 2021-06-30 12:02:00.406
4 | Joaquim | Sim | 2018-06-30 12:10:07.152

Perceba que a exclus√£o f√≠sica do registro de `id=3` continuar√° existindo. A exclus√£o l√≥gica do registro de `id=2`, por√©m, funcionou como esperado.

Pontos de aten√ß√£o:

- Esse √© o modo que exige maior consumo de recursos de banda e mem√≥ria. 
- Por n√£o gerar leituras idempotentes, exige que o destino consiga tratar entradas duplicadas.
- O ajuste fino envolvendo intervalo de _polling_, tempo de reten√ß√£o do t√≥pico e otimiza√ß√£o da _query_ √© essencial.
- Use somente quando as tabelas forem muito pequenas, forem limpas frequentemente, ou como _fallback_ caso n√£o possuam chave num√©rica estritamente crescente e/ou campo de data de atualiza√ß√£o.

### Modo incremental

Traz somente registros novos, baseados em um identificador √∫nico, num√©rico e estritamente crescente.

A cada intervalo de _polling_ uma _query_ `SELECT` √© executada com a inclus√£o de condi√ß√£o `WHERE` pelo conector, de forma a obter somente os identificadores cujos valores s√£o maiores do que o maior obtido anteriormente. Todos os registros retornados s√£o publicados no t√≥pico.

Exemplo:

Considere os dados na tabela de origem:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
1 | Maria   | Sim | 2020-12-01 16:22:15.170
2 | Ant√¥nio | Sim | 2010-02-14 04:35:04.041
3 | Estela  | Sim | 2021-06-30 12:02:00.406

Considere um conector configurado para ler todas as colunas da tabela, e utilizar a coluna `id` como chave do t√≥pico e coluna de detec√ß√£o de incremento. Ap√≥s a primeira consulta, o t√≥pico conter√° algo como:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
1 | Maria   | Sim | 2020-12-01 16:22:15.170
2 | Ant√¥nio | Sim | 2010-02-14 04:35:04.041
3 | Estela  | Sim | 2021-06-30 12:02:00.406

O t√≥pico se manter√° assim at√© que uma linha com `id > 3` seja encontrada.

Alguns intervalos depois, uma nova linha √© inserida:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
1 | Maria   | Sim | 2020-12-01 16:22:15.170
2 | Ant√¥nio | Sim | 2010-02-14 04:35:04.041
3 | Estela  | Sim | 2021-06-30 12:02:00.406
4 | Joaquim | Sim | 2018-06-30 12:10:07.152

O t√≥pico consome somente a linha nova:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
4 | Joaquim  | Sim | 2018-06-30 12:10:07.152

O t√≥pico ter√° algo como:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
1 | Maria   | Sim | 2020-12-01 16:22:15.170
2 | Ant√¥nio | Sim | 2010-02-14 04:35:04.041
3 | Estela  | Sim | 2021-06-30 12:02:00.406
4 | Joaquim | Sim | 2018-06-30 12:10:07.152

Dias depois, a segunda linha √© exclu√≠da, a terceira √© alterada e √© inclu√≠da uma quinta, deixando a tabela assim:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
1 | Maria   | Sim | 2020-12-01 16:22:15.170
3 | Estela  | N√£o | 2021-07-01 00:00:00.000
4 | Joaquim | Sim | 2018-06-30 12:10:07.152
5 | Tereza  | Sim | 2021-07-01 00:00:00.000

Ser√° consumida somente a linha nova:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
5 | Tereza  | Sim | 2021-07-01 00:00:00.000

E o t√≥pico conter√° algo do tipo:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
1 | Maria   | Sim | 2020-12-01 16:22:15.170
2 | Ant√¥nio | Sim | 2010-02-14 04:35:04.041
3 | Estela  | Sim | 2021-06-30 12:02:00.406
4 | Joaquim | Sim | 2018-06-30 12:10:07.152
5 | Tereza  | Sim | 2021-07-01 00:00:00.000

Os mesmos dados acima estar√£o em um destino que monitore o t√≥pico.

Perceba que atualiza√ß√µes e exclus√µes n√£o s√£o capturadas nesse modo. Cada linha √© lida somente uma vez, e seu estado no t√≥pico √© imut√°vel.

Pontos de aten√ß√£o:

- Esse √© o modo de menor _footprint_. Exige a menor quantidade poss√≠vel de processamento, mem√≥ria e banda.
- Por gerar leituras idempotentes, n√£o exige que o destino consiga tratar entradas duplicadas.
- A coluna identificadora dever√° sempre ser indexada e √∫nica. De maneira geral, as chaves-prim√°rias s√£o as mais adequadas, pois n√£o exigem o uso de √≠ndices adicionais.
- Use somente em situa√ß√µes onde a tabela de origem cont√©m dados imut√°veis e perenes, como em uma tabela de fatos.

### Modo data/hora

Traz somente registros em que uma coluna de data/hora seja estritamente maior do que o maior valor obtido anteriormente.

A cada intervalo de _polling_ uma _query_ `SELECT` √© executada com a inclus√£o de condi√ß√£o `WHERE` pelo conector, de forma a obter somente os registros cujos valores na coluna indicada sejam maiores do que o maior obtido anteriormente. Todos os registros retornados s√£o publicados no t√≥pico.

Exemplo:

Considere os dados na tabela de origem:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
1 | Maria   | Sim | 2020-12-01 16:22:15.170
2 | Ant√¥nio | Sim | 2010-02-14 04:35:04.041
3 | Estela  | Sim | 2021-06-30 12:02:00.406

Considere um conector configurado para ler todas as colunas da tabela, e utilizar a coluna `id` como chave do t√≥pico, e `atualizado_em` como a coluna de data/hora. Ap√≥s a primeira consulta, o t√≥pico conter√° algo como:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
1 | Maria   | Sim | 2020-12-01 16:22:15.170
2 | Ant√¥nio | Sim | 2010-02-14 04:35:04.041
3 | Estela  | Sim | 2021-06-30 12:02:00.406

O t√≥pico se manter√° assim at√© que uma linha com `atualizado_em > '2021-06-30 12:02:00.406'` seja encontrada.

Algum tempo depois, a segunda linha √© exclu√≠da, a terceira √© alterada e √© inclu√≠da uma quarta e uma quinta, deixando a tabela assim:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
1 | Maria   | Sim | 2020-12-01 16:22:15.170
3 | Estela  | N√£o | 2021-07-01 00:00:00.000
4 | Joaquim | Sim | 2018-06-30 12:10:07.152
5 | Tereza  | Sim | 2021-07-01 00:00:00.000

Ser√£o consumidas as linhas:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
3 | Estela  | N√£o | 2021-07-01 00:00:00.000
5 | Tereza  | Sim | 2021-07-01 00:00:00.000

Perceba que a exclus√£o n√£o foi detectada. A linha inclu√≠da com `id=4` n√£o √© retornada porque a coluna `atualizado_em` recebeu um valor menor ou igual ao maior valor obtido anteriormente. A linha editada com `id=3` √© retornada com os valores atualizados, assim com a linha com com `id=5`, mesmo ambas tendo o mesmo valor de `atualizado_em`.

E o t√≥pico conter√° algo do tipo:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
1 | Maria   | Sim | 2020-12-01 16:22:15.170
2 | Ant√¥nio | Sim | 2010-02-14 04:35:04.041
3 | Estela  | Sim | 2021-06-30 12:02:00.406
3 | Estela  | N√£o | 2021-07-01 00:00:00.000
5 | Tereza  | Sim | 2021-07-01 00:00:00.000

Em um destino que monitore o t√≥pico, teremos:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
1 | Maria   | Sim | 2020-12-01 16:22:15.170
2 | Ant√¥nio | Sim | 2010-02-14 04:35:04.041
3 | Estela  | N√£o | 2021-07-01 00:00:00.000
5 | Tereza  | Sim | 2021-07-01 00:00:00.000

A configura√ß√£o `batch.max.rows` (padr√£o `100`) permite indicar quanto registro ser√£o lidos a cada consulta efetuada na origem. Isso gera efeitos colaterais indesejados nesse modo. Observe.

Em seguida, foram adicionadas 150 linhas novas em lote, todas como mesmo valor na coluna `atualizado_em`. Uma nova linha ainda foi adicionada antes do pr√≥ximo intervalo de _poll_ com `id=156`. A tabela conter√° algo como:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
1 | Maria   | Sim | 2020-12-01 16:22:15.170
3 | Estela  | N√£o | 2021-07-01 00:00:00.000
4 | Joaquim | Sim | 2018-06-30 12:10:07.152
5 | Tereza  | Sim | 2021-07-01 00:00:00.000
6 | Astolfo | Sim | 2021-07-01 12:25:00.000
... | ...     | ... | 2021-07-01 12:25:00.000
105 | Ana     | Sim | 2021-07-01 12:25:00.000
106 | Jorge   | Sim | 2021-07-01 12:25:00.000
... | ...     | ... | 2021-07-01 12:25:00.000
155 | Fel√≠cia | Sim | 2021-07-01 12:25:00.000
156 | Gen√©sio | Sim | 2021-07-01 12:27:35.373

Ser√£o consumidas as pr√≥ximas 100 linhas:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
6 | Astolfo | Sim | 2021-07-01 12:25:00.000
... | ...     | ... | 2021-07-01 12:25:00.000
105 | Ana     | Sim | 2021-07-01 12:25:00.000

O t√≥pico ter√°:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
1 | Maria   | Sim | 2020-12-01 16:22:15.170
2 | Ant√¥nio | Sim | 2010-02-14 04:35:04.041
3 | Estela  | Sim | 2021-06-30 12:02:00.406
3 | Estela  | N√£o | 2021-07-01 00:00:00.000
5 | Tereza  | Sim | 2021-07-01 00:00:00.000
6 | Astolfo | Sim | 2021-07-01 12:25:00.000
... | ...     | ... | 2021-07-01 12:25:00.000
105 | Ana     | Sim | 2021-07-01 12:25:00.000

No pr√≥ximo _poll_, ser√£o consumidas somente linhas com `atualizado_em > '2021-07-01 12:25:00.000'`:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
156 | Gen√©sio | Sim | 2021-07-01 12:27:35.373

No t√≥pico teremos:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
1 | Maria   | Sim | 2020-12-01 16:22:15.170
2 | Ant√¥nio | Sim | 2010-02-14 04:35:04.041
3 | Estela  | Sim | 2021-06-30 12:02:00.406
3 | Estela  | N√£o | 2021-07-01 00:00:00.000
5 | Tereza  | Sim | 2021-07-01 00:00:00.000
6 | Astolfo | Sim | 2021-07-01 12:25:00.000
... | ...     | ... | 2021-07-01 12:25:00.000
105 | Ana     | Sim | 2021-07-01 12:25:00.000
156 | Gen√©sio | Sim | 2021-07-01 12:27:35.373

Perceba que as linhas com `id` entre `106` e `155` (inclusive) nunca ser√£o consumidas.

Em seguida, as linhas com `id` nos valores `1` e `137` s√£o alterados para:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
1 | Maria   | N√£o | 2021-07-01 12:29:19.736
... | ...     | ... | ...
137 | Let√≠cia | N√£o | 2021-07-01 12:29:19.938
... | ...     | ... | ...

Os registros s√£o consumidos e no t√≥pico teremos:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
1 | Maria   | Sim | 2020-12-01 16:22:15.170
2 | Ant√¥nio | Sim | 2010-02-14 04:35:04.041
3 | Estela  | Sim | 2021-06-30 12:02:00.406
3 | Estela  | N√£o | 2021-07-01 00:00:00.000
5 | Tereza  | Sim | 2021-07-01 00:00:00.000
6 | Astolfo | Sim | 2021-07-01 12:25:00.000
... | ...     | ... | 2021-07-01 12:25:00.000
105 | Ana     | Sim | 2021-07-01 12:25:00.000
156 | Gen√©sio | Sim | 2021-07-01 12:27:35.373
1 | Maria   | N√£o | 2021-07-01 12:29:19.736
137 | Let√≠cia | N√£o | 2021-07-01 12:29:19.938

O registro que n√£o havia sido consumido anteriormente agora ser√° inclu√≠do, bem como altera√ß√µes em registros existentes.

Pontos de aten√ß√£o:

- Esse √© o modo que necessita de maior aten√ß√£o para ser utilizado. Use com muita cautela. Se poss√≠vel, n√£o utilize.
- Por n√£o gerar leituras idempotentes, exige que o destino consiga tratar entradas duplicadas.
- A coluna de data/hora deve ser indexada na origem, apesar de n√£o necessitar ser necessariamente √∫nica.
- N√£o identifica altera√ß√µes que n√£o modifiquem o valor da coluna de data/hora.
- Use somente quando sua coluna de data/hora contiver a data de atualiza√ß√£o do registro, e haja garantia de que n√£o ser√£o gravados valores diferentes (anteriores ou posteriores) do _timestamp_ do momento da grava√ß√£o (como por exemplo, data/hora obtidos na aplica√ß√£o e n√£o no SGBD em sistemas multiprodutores de registros). Ainda assim use somente se n√£o for poss√≠vel utilizar o modo composto data/hora e incremental.

### Modo composto data/hora e incremental

Combina os filtros dos modos incremental e data/hora para detectar altera√ß√µes e inser√ß√µes, linha a linha.

A cada intervalo de _polling_ uma _query_ `SELECT` √© executada com a inclus√£o de condi√ß√£o `WHERE` pelo conector, de forma a obter somente os identificadores cujos valores s√£o maiores do que o maior obtido anteriormente (uma inser√ß√£o), ou cujos valores na coluna indicada sejam maiores do que o maior obtido anteriormente para o mesmo identificador (uma atualiza√ß√£o). Ou seja, detecta qualquer altera√ß√£o na tupla {[_coluna identificadora ascendente √∫nica_], [_coluna data/hora ascendente_]}. Todos os registros retornados s√£o publicados no t√≥pico.

Exemplo:

Considere os dados na tabela de origem:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
1 | Maria   | Sim | 2020-12-01 16:22:15.170
2 | Ant√¥nio | Sim | 2010-02-14 04:35:04.041
3 | Estela  | Sim | 2021-06-30 12:02:00.406

Considere um conector configurado para ler todas as colunas da tabela, e utilizar a coluna `id` como chave do t√≥pico e coluna de detec√ß√£o de incremento, e `atualizado_em` como a coluna de data/hora. Ap√≥s a primeira consulta, o t√≥pico conter√° algo como:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
1 | Maria   | Sim | 2020-12-01 16:22:15.170
2 | Ant√¥nio | Sim | 2010-02-14 04:35:04.041
3 | Estela  | Sim | 2021-06-30 12:02:00.406

O t√≥pico se manter√° assim at√© que uma linha com `id > 3` ou com `atualizado_em > '2021-06-30 12:02:00.406'` seja encontrada.

Algum tempo depois, a segunda linha √© exclu√≠da, a terceira √© alterada e √© inclu√≠da uma quarta e uma quinta, deixando a tabela assim:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
1 | Maria   | Sim | 2020-12-01 16:22:15.170
3 | Estela  | N√£o | 2021-07-01 00:00:00.000
4 | Joaquim | Sim | 2018-06-30 12:10:07.152
5 | Tereza  | Sim | 2021-07-01 00:00:00.000

Ser√£o consumidas as linhas:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
3 | Estela  | N√£o | 2021-07-01 00:00:00.000
4 | Joaquim | Sim | 2018-06-30 12:10:07.152
5 | Tereza  | Sim | 2021-07-01 00:00:00.000

Perceba que a exclus√£o n√£o foi detectada. As linhas inclu√≠das com s√£o retornadas porque a coluna `id` recebeu valores maiores que o maior valor obtido anteriormente (mesmo sendo na linha com `id=4` a data de atualiza√ß√£o inferior ao maior valor obtido anteriormente). A linha editada com `id=3` √© retornada com os valores atualizados.

E o t√≥pico conter√° algo do tipo:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
1 | Maria   | Sim | 2020-12-01 16:22:15.170
2 | Ant√¥nio | Sim | 2010-02-14 04:35:04.041
3 | Estela  | Sim | 2021-06-30 12:02:00.406
3 | Estela  | N√£o | 2021-07-01 00:00:00.000
4 | Joaquim | Sim | 2018-06-30 12:10:07.152
5 | Tereza  | Sim | 2021-07-01 00:00:00.000

Em um destino que monitore o t√≥pico, teremos:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
1 | Maria   | Sim | 2020-12-01 16:22:15.170
2 | Ant√¥nio | Sim | 2010-02-14 04:35:04.041
3 | Estela  | N√£o | 2021-07-01 00:00:00.000
4 | Joaquim | Sim | 2018-06-30 12:10:07.152
5 | Tereza  | Sim | 2021-07-01 00:00:00.000

Perceba que ainda n√£o s√£o detectadas as exclus√µes, por√©m as altera√ß√µes e inser√ß√µes funcionam como esperado.

A quest√£o do `batch.max.rows` tamb√©m √© resolvida. Como a identifica√ß√£o de cada registro √© feita pela combina√ß√£o das duas colunas, o conector consegue detectar que a altera√ß√£o foi a mais recente para aquele identificador espec√≠fico, inclu√≠ndo o registro no t√≥pico. Observe a diferen√ßa.

Em seguida, foram adicionadas 150 linhas novas em lote, todas como mesmo valor na coluna `atualizado_em`. Uma nova linha ainda foi adicionada antes do pr√≥ximo intervalo de _poll_ com `id=156`. A tabela conter√° algo como:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
1 | Maria   | Sim | 2020-12-01 16:22:15.170
3 | Estela  | N√£o | 2021-07-01 00:00:00.000
4 | Joaquim | Sim | 2018-06-30 12:10:07.152
5 | Tereza  | Sim | 2021-07-01 00:00:00.000
6 | Astolfo | Sim | 2021-07-01 12:25:00.000
... | ...     | ... | 2021-07-01 12:25:00.000
105 | Ana     | Sim | 2021-07-01 12:25:00.000
106 | Jorge   | Sim | 2021-07-01 12:25:00.000
... | ...     | ... | 2021-07-01 12:25:00.000
155 | Fel√≠cia | Sim | 2021-07-01 12:25:00.000
156 | Gen√©sio | Sim | 2021-07-01 12:27:35.373

Ser√£o consumidas as pr√≥ximas 100 linhas:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
6 | Astolfo | Sim | 2021-07-01 12:25:00.000
... | ...     | ... | 2021-07-01 12:25:00.000
105 | Ana     | Sim | 2021-07-01 12:25:00.000

No pr√≥ximo _poll_ ser√£o consumidas as linhas restantes:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
106 | Jorge   | Sim | 2021-07-01 12:25:00.000
... | ...     | ... | 2021-07-01 12:25:00.000
155 | Fel√≠cia | Sim | 2021-07-01 12:25:00.000
156 | Gen√©sio | Sim | 2021-07-01 12:27:35.373

Teremos todos os registros no t√≥pico, como esperado.

Em seguida, as linhas com `id` nos valores `1` e `137` s√£o alterados para:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
1 | Maria   | N√£o | 2021-07-01 12:29:19.736
... | ...     | ... | ...
137 | Let√≠cia | N√£o | 2021-07-01 12:29:19.938
... | ...     | ... | ...

Os registros s√£o consumidos e no t√≥pico teremos:

id | nome | ativo | atualizado_em
--- | --- | --- | ---
1 | Maria   | Sim | 2020-12-01 16:22:15.170
2 | Ant√¥nio | Sim | 2010-02-14 04:35:04.041
3 | Estela  | Sim | 2021-06-30 12:02:00.406
3 | Estela  | N√£o | 2021-07-01 00:00:00.000
5 | Tereza  | Sim | 2021-07-01 00:00:00.000
6 | Astolfo | Sim | 2021-07-01 12:25:00.000
... | ...     | ... | 2021-07-01 12:25:00.000
105 | Ana     | Sim | 2021-07-01 12:25:00.000
106 | Jorge   | Sim | 2021-07-01 12:25:00.000
... | ...     | ... | 2021-07-01 12:25:00.000
155 | Fel√≠cia | Sim | 2021-07-01 12:25:00.000
156 | Gen√©sio | Sim | 2021-07-01 12:27:35.373
1 | Maria   | N√£o | 2021-07-01 12:29:19.736
137 | Let√≠cia | N√£o | 2021-07-01 12:29:19.938

Todas as altera√ß√µes cujos identificadores sejam novos, ou cujas datas de atualiza√ß√£o sejam superiores √†s anteriormente lidas para aquele registro s√£o consumidas. Exclus√µes n√£o, por√©m.

Pontos de aten√ß√£o:

- Esse √© o modo mais seguro.
- Assume que a tabela de origem possui uma coluna com um n√∫mero inteiro que seja um identificador √∫nico ascendente e tamb√©m uma coluna contendo data/hora da √∫ltima atualiza√ß√£o, ascendente por√©m n√£o necessariamente √∫nica.
- Identifica unicamente a √∫ltima vers√£o de uma linha pela tupla formada pelas colunas citadas acima.
- N√£o identifica altera√ß√µes que n√£o alterem a data de atualiza√ß√£o, ou que a altere para valores n√£o maiores do que o anteriormente obtido para essa linha. Isso exige que esta coluna seja garantidamente mantida coesa (monotonicamente crescente) e com a maior precis√£o poss√≠vel.
- Por n√£o gerar leituras idempotentes, exige que o destino consiga tratar entradas duplicadas. Isso restringe o uso de colunas auto-incrementais (inclusive nas chaves-prim√°rias) e outras _constraints_ na tabela de destino envolvendo as colunas da tupla identificadora, e potencialmente em rela√ß√µes com outras tabelas.
- As colunas da tupla identificadora devem constituir um √≠ndice na origem, por quest√µes de desempenho.
- Para implementar a detec√ß√£o de exclus√µes, use exclus√£o l√≥gica (como na coluna `ativo` dos exemplos). Nesse caso, a exclus√£o f√≠sica n√£o acontece, somente uma atualiza√ß√£o.

## Modos de grava√ß√£o do JDBC Sink

Ao consumir os dados de um t√≥pico, o conector _sink_ vai tentar atualizar a tabela de destino.

A primeira coisa a se configurar √© a chave-prim√°ria. Isso vai indicar ao Kafka a sem√¢ntica dos dados no t√≥pico e na tabela de destino.

- `pk.mode=record_key` indica que a chave-prim√°ria est√° na chave do t√≥pico.
- `pk.mode=record_value` indica que a chave-prim√°ria est√° no valor do t√≥pico.
- `pk.fields` indica quais s√£o as colunas que comp√µem a chave-prim√°ria, na localiza√ß√£o indicada em `pk.mode`.

üê±‚Äçüë§ _Tamb√©m √© poss√≠vel n√£o indicar a chave-prim√°ria, ou deixar que o Kafka gere um identificador √∫nico. Ambas alternativas podem constituir casos de uso interessantes, mas n√£o ser√£o discutidas aqui._

Identificando a sem√¢ntica dos valores, o Kafka Connect pode gerar as _queries_ DML para equalizar as tabelas. Ser√£o utilizados os mesmos nomes de colunas contidos no esquema dos dados.

Devemos configurar o modo de grava√ß√£o. O padr√£o √© `insert.mode=insert`, onde todas as entradas lidas do t√≥pico formar√£o uma _query_ de `INSERT`.

Esse cen√°rio √© perfeito para tabelas e t√≥picos de fatos, onde somente teremos inclus√µes, por√©m √© bastante limitada se desejarmos espelhar altera√ß√µes de registros. Al√©m disso, o ideal √© conseguir garantir que sejam feitas grava√ß√µes idempotentes, permitindo a recupera√ß√£o em caso de falha do processo.

Usando `insert.mode=upsert`, o Kafka Connect ser√° capaz de gerar o comando adequado de acordo com a plataforma, para realizar a a√ß√£o atomicamente. Por exemplo, em MySQL ser√£o gerados `INSERT .. ON DUPLICATE KEY UPDATE ..` e em SQL Server `MERGE ..`.

## Exclus√µes f√≠sicas e DDL

Quando configurado para executar exclus√µes f√≠sicas, o conector de _sink_ deve receber um registro com o valor da chave desejada e com os valores dos campos nulos. Isso deve ser feito por outra ferramenta, j√° que o conector _source_ n√£o tem essa capacidade.

H√° a possibilidade de se configurar a _task_ para gerar os comandos DDL implementando auto cria√ß√£o e auto evolu√ß√£o das tabelas. Isso exige permiss√£o adequada no usu√°rio de login do conector.

## Exemplos de uso

Ser√° utilizado o banco de dados de exemplo [organizacao-db](https://github.com/ermogenes/organizacao-db), com os dados no MySQL sendo transportados para o SQL Server.

Para baixar e subir o ambiente contendo Kafka Connect, MySQL e SQL Server, fa√ßa:

```
git clone https://github.com/ermogenes/organizacao-db.git
cd organizacao-db
docker compose --file dc-mysql-com-dados-kafka.yml up
```

Acesse o Kafka UI em [http://localhost:3030](http://localhost:3030) e crie as _tasks_.

Todos os exemplos assumem exclus√£o l√≥gica (exclus√µes f√≠sicas n√£o s√£o tratadas).

### Modo data/hora e incremento

Os dados da tabela `pessoa` ser√£o sincronizados com _upserts_, baseados na chave-prim√°ria e na data de atualiza√ß√£o.

[_*Source*_](integracao-de-bases-de-dados-relacionais-com-kafka-connect-jdbc/01-pessoa-source-mysql.properties)

```ini
name=source-mysql-orgdb-pessoa
connector.class=io.confluent.connect.jdbc.JdbcSourceConnector
connection.url=jdbc:mysql://mysql:3306/
connection.user=root
connection.password=root
mode=timestamp+incrementing
catalog.pattern=organizacao
table.whitelist=pessoa
incrementing.column.name=id
timestamp.column.name=data_atualizacao
topic.prefix=mysql-orgdb-
transforms=createKey,extractInt
transforms.createKey.type=org.apache.kafka.connect.transforms.ValueToKey
transforms.createKey.fields=id
transforms.extractInt.type=org.apache.kafka.connect.transforms.ExtractField$Key
transforms.extractInt.field=id
tasks.max=1
```

[_*Sink*_](integracao-de-bases-de-dados-relacionais-com-kafka-connect-jdbc/02-pessoa-sink-sqlserver.properties)

```ini
name=sink-sqlserver-orgdb-pessoa
connector.class=io.confluent.connect.jdbc.JdbcSinkConnector
topics=mysql-orgdb-pessoa
connection.url=jdbc:sqlserver://sqlserver:1433
connection.user=sa
connection.password=My_secret_!2#4%
table.name.format=organizacao.dbo.pessoa
insert.mode=upsert
pk.mode=record_key
pk.fields=id
tasks.max=1
```

### Modo incremento

Os dados da tabela `evento` ser√£o sincronizados com _inserts_, baseados na chave-prim√°ria.

[_*Source*_](integracao-de-bases-de-dados-relacionais-com-kafka-connect-jdbc/03-evento-source-mysql.properties)

```ini
name=source-mysql-orgdb-evento
connector.class=io.confluent.connect.jdbc.JdbcSourceConnector
connection.url=jdbc:mysql://mysql:3306/
connection.user=root
connection.password=root
mode=incrementing
catalog.pattern=organizacao
table.whitelist=evento
incrementing.column.name=id
topic.prefix=mysql-orgdb-
transforms=createKey,extractInt
transforms.createKey.type=org.apache.kafka.connect.transforms.ValueToKey
transforms.createKey.fields=id
transforms.extractInt.type=org.apache.kafka.connect.transforms.ExtractField$Key
transforms.extractInt.field=id
tasks.max=1
```

[_*Sink*_](integracao-de-bases-de-dados-relacionais-com-kafka-connect-jdbc/04-evento-sink-sqlserver.properties)

```ini
name=sink-sqlserver-orgdb-evento
connector.class=io.confluent.connect.jdbc.JdbcSinkConnector
topics=mysql-orgdb-evento
connection.url=jdbc:sqlserver://sqlserver:1433
connection.user=sa
connection.password=My_secret_!2#4%
table.name.format=organizacao.dbo.evento
insert.mode=insert
pk.mode=record_key
pk.fields=id
tasks.max=1
```

### Modo em massa

Os dados da tabela `papel` ser√£o sincronizados em massa.

[_*Source*_](integracao-de-bases-de-dados-relacionais-com-kafka-connect-jdbc/05-papel-source-mysql.properties)

```ini
name=source-mysql-orgdb-papel
connector.class=io.confluent.connect.jdbc.JdbcSourceConnector
connection.url=jdbc:mysql://mysql:3306/
connection.user=root
connection.password=root
mode=bulk
poll.interval.ms=60000
catalog.pattern=organizacao
table.whitelist=papel
topic.prefix=mysql-orgdb-
transforms=createKey,extractInt
transforms.createKey.type=org.apache.kafka.connect.transforms.ValueToKey
transforms.createKey.fields=id
transforms.extractInt.type=org.apache.kafka.connect.transforms.ExtractField$Key
transforms.extractInt.field=id
tasks.max=1
```

[_*Sink*_](integracao-de-bases-de-dados-relacionais-com-kafka-connect-jdbc/06-papel-sink-sqlserver.properties)

```ini
name=sink-sqlserver-orgdb-papel
connector.class=io.confluent.connect.jdbc.JdbcSinkConnector
topics=mysql-orgdb-papel
connection.url=jdbc:sqlserver://sqlserver:1433
connection.user=sa
connection.password=My_secret_!2#4%
table.name.format=organizacao.dbo.papel
insert.mode=upsert
pk.mode=record_key
pk.fields=id
tasks.max=1
```


