# Conceitos b√°sicos

## Introdu√ß√£o

O [Apache Kafka](https://kafka.apache.org/) √© um sistema distribu√≠do em software livre que implementa a arquitetura de fluxo de eventos, e que na pr√°tica permite a base tecnol√≥gica para a cria√ß√£o e integra√ß√£o de sistemas de alta disponibilidade em tempo real.

A gama de casos de uso poss√≠veis √© bem vasta, por√©m bastante espec√≠fica. Certifique-se de que o Kafka √© a ferramenta correta para o seu problema antes de utiliz√°-lo.

Este material √© autoral, fruto de estudos informais. Refira-se √† [documenta√ß√£o oficial](https://kafka.apache.org/documentation/) sempre que necess√°rio e ao sentir algum estranhamento em rela√ß√£o ao que foi escrito.

## Infraestrutura

Pode ser instalado no Windows ou Mac, mas preferencialmente em Linux. Consiste em dois softwares principais, o Kafka e o ZooKeeper, bem como diversas outras ferramentas de apoio.

- **Apache Kafka** faz toda a m√°gica acontecer.
- **ZooKeeper** faz a gest√£o e coordena√ß√£o das inst√¢ncias.

√â poss√≠vel utilizar clientes em praticamente todas as plataformas populares de desenvolvimento.

### _Brokers_ e _clusters_

Cada inst√¢ncia de servidor Kafka √© chamada de _broker_. √â respons√°vel por todas as a√ß√µes de persist√™ncia e leitura.

Pode ser organizado em conjuntos de _brokers_ chamados _clusters_, idealmente com 3 ou mais inst√¢ncias, podendo alcan√ßar 100 (ou mais) em grandes projetos.

Em um _cluster_, cada _broker_ √© identificado por um n√∫mero identificador inteiro. Os metadados s√£o conhecidos por todos os _brokers_ igualmente, de forma que n√£o h√° um endere√ßo de _cluster_ e qualquer um deles ao ser endere√ßado atua como _bootstrap server_ provendo acesso ao _cluster_ como um todo. Nenhum _broker_ possui todos os dados, pois eles ficam distribu√≠dos.

Pode-se conseguir alta disponibilidade utilizando replica√ß√£o. O fator de replica√ß√£o expressa quantas r√©plicas ser√£o mantidas dos dados, em _brokers_ diferentes. Assim, o fator de replica√ß√£o varia entre 1 e o n√∫mero de _brokers_ do _cluster_. Um _cluster_ com `N` _brokers_ √© tolerante a falhas em `N-1` deles simultaneamente. Por exemplo, com 3 _brokers_ podemos ter um com falha, um em atualiza√ß√£o e um terceiro mantendo o sistema dispon√≠vel.

A coordena√ß√£o √© feita automaticamente pelo ZooKeeper. Um dos _brokers_ ser√° eleito o l√≠der e ser√° respons√°vel por receber e entregar os dados. Os demais atuar√£o como r√©plicas, mantendo os dados sincronizados (_in-sync replica_ ou ISR). Essa gest√£o √© feita para cada parti√ß√£o  em cada t√≥pico, portanto a carga pode ser balanceada adequadamente.

Al√©m de gerenciar os _brokers_ em um _cluster_ e coordenar a lideran√ßa de parti√ß√£o, o ZooKeeper tamb√©m notifica os _brokers_ sobre mudan√ßas na estrutura, mantendo os metadados atualizados em todos os servidores. Com tantas atribui√ß√µes, o ZooKeeper √© obrigat√≥rio, mesmo que haja somente um _broker_.

O pr√≥prio ZooKeeper deve ser preferencialmente mantido em um _cluster_, sempre com n√∫mero √≠mpar de servidores. Eles elegem um l√≠der, que trata as entradas (_write_), com os demais seguidores efetuando as sa√≠das (_read_).

O ZooKeeper √© transparente aos consumidores e produtores, e acessado somente pelo Kafka.

## Modelo de armazenamento

Podemos pensar no Kafka como um grande _log_, onde dados em fluxo s√£o armazenados em uma sequ√™ncia temporal imut√°vel, para serem consumidos ordenadamente. Dados de mesma natureza s√£o agrupados em _t√≥picos_, e os t√≥picos s√£o gravados em arquivos f√≠sicos distribu√≠dos entre os _brokers_ chamados _parti√ß√µes_.

Os dados s√£o retidos por um tempo finito no Kafka (ex. 1 semana), portanto n√£o s√£o indefinidamente persistentes. Considere casos de uso de dados em movimento, e n√£o de dados em repouso.

### T√≥picos

Os t√≥picos s√£o agrupamentos de dados de mesma categoria. Atuam como tabelas em um banco relacional, por√©m sem as _constraints_. Outra diferen√ßa importante √© a impossibilidade de altera√ß√£o dos dados: os dados s√£o imut√°veis. Podem-se criar quantos t√≥picos forem necess√°rios, e cada t√≥pico pode receber dados de m√∫ltiplas origens e entregar dados para m√∫ltiplos destinos.

Ao criar um t√≥pico definimos um nome identificador, a quantidade de parti√ß√µes desejadas, e a quantidade de r√©plicas que estar√£o dispon√≠veis.

Ao se produzir uma mensagem (ou seja, gravar um mensagem em um t√≥pico) o Kafka verifica se o t√≥pico existe (cria com a configura√ß√£o padr√£o se n√£o existir), l√™ os seus metadados com as parti√ß√µes e configura√ß√µes de replica√ß√£o, e efetua a grava√ß√£o. Ap√≥s a grava√ß√£o, a mensagem estar√° dispon√≠vel para todos os consumidores interessados no t√≥pico.

### Parti√ß√µes

Os dados de um t√≥pico s√£o gravados em arquivos f√≠sicos de dados, chamados parti√ß√µes. As parti√ß√µes s√£o numeradas sequencialmente, a partir de `0`. Ter mais de uma parti√ß√£o permite que os dados e a carga sejam distribu√≠dos, aumentando a toler√¢ncia a falhas e a disponibilidade.

Caso estejamos em um _cluster_, elas ser√£o distribu√≠das entre os _brokers_ dispon√≠veis, a crit√©rio do Kafka.

Exemplo:

Em um _cluster_ com 3 _brokers_ `1`, `2` e `3`, s√£o criados os t√≥picos `A` com 3 parti√ß√µes, `B` com 4 parti√ß√µes, `C` com 2 parti√ß√µes, e `D` com 1 parti√ß√£o.

- O t√≥pico `A` ter√° suas parti√ß√µes divididas igualmente entre os _brokers_, possivelmente um em cada;
- O t√≥pico `B` ter√° suas parti√ß√µes divididas igualmente entre os _brokers_ com um _broker_ que recebendo mais de uma parti√ß√£o desse t√≥pico;
- O t√≥pico `C` ter√° suas parti√ß√µes divididas entre os _brokers_, com algum _broker_ n√£o recebendo nenhuma parti√ß√£o;
- O t√≥pico `D` ter√° sua √∫nica parti√ß√£o alocada em um √∫nico _broker_.

Uma poss√≠vel configura√ß√£o final seria:

- _Broker_ `1`
  - T√≥pico `A` Parti√ß√£o `1`
  - T√≥pico `B` Parti√ß√£o `2`
  - T√≥pico `C` Parti√ß√£o `0`
  - T√≥pico `D` Parti√ß√£o `0`
- _Broker_ `2`
  - T√≥pico `A` Parti√ß√£o `0`
  - T√≥pico `B` Parti√ß√£o `1`
  - T√≥pico `B` Parti√ß√£o `3`
- _Broker_ `3`
  - T√≥pico `A` Parti√ß√£o `2`
  - T√≥pico `B` Parti√ß√£o `0`
  - T√≥pico `C` Parti√ß√£o `1`

Em uma vis√£o por t√≥pico:

- T√≥pico `A`
  - Parti√ß√£o `0` no _Broker_ `2`
  - Parti√ß√£o `1` no _Broker_ `1`
  - Parti√ß√£o `2` no _Broker_ `3`
- T√≥pico `B`
  - Parti√ß√£o `0` no _Broker_ `3`
  - Parti√ß√£o `1` no _Broker_ `2`
  - Parti√ß√£o `2` no _Broker_ `1`
  - Parti√ß√£o `3` no _Broker_ `2`
- T√≥pico `C`
  - Parti√ß√£o `0` no _Broker_ `1`
  - Parti√ß√£o `1` no _Broker_ `3`
- T√≥pico `D`
  - Parti√ß√£o `0` no _Broker_ `1`

### Replica√ß√£o

Em um t√≥pico criado com o fator de replica√ß√£o padr√£o `1`, cada parti√ß√£o cont√©m dados distintos, de forma que cada dado est√° em uma e somente uma parti√ß√£o. Se definirmos um n√∫mero maior de replica√ß√£o, haver√£o c√≥pias f√≠sicas da parti√ß√£o (chamadas _in-sync replicas_ ou _ISRs_) distribu√≠das necessariamente em _brokers_ diferentes, inativas e sincronizadas para assumir em caso de falha da parti√ß√£o ativa (chamada de parti√ß√£o l√≠der).

O fator de replica√ß√£o, portanto, √© definido entre 1 e a quantidade de _brokers_ existentes no _cluster_.

Sempre haver√° uma parti√ß√£o l√≠der eleita entre as r√©plicas, que atender√° toda a carga. As demais se manter√£o como c√≥pias est√°ticas sincronizadas, podendo assumir a lideran√ßa eventualmente a crit√©rio do Kafka.

### Dados, produtores e consumidores

Os s√£o mantidos nos t√≥picos, ap√≥s derem recebidos como _payloads_ da mensagens enviadas pelas aplica√ß√µes com o papel de produtores, e sob demanda entregues √†s aplica√ß√µes com o papel de consumidores.

Os dados s√£o armazenados e transportados em forma bin√°ria em _arrays_ de _bytes_. Assim, devemos tratar nos produtores e consumidores a serializa√ß√£o dos dados apropriada ao caso de uso. As bibliotecas costumam incluir diversos serializadores para formatos comuns.

#### Produ√ß√£o

Os produtores escrevem dados nos t√≥picos. N√£o √© necess√°rio saber qual a parti√ß√£o ou qual _broker_ acessar, mas somente o endere√ßo de um dos _brokers_ do _cluster_ e o nome do t√≥pico. Toda a resolu√ß√£o √© feita pelo Kafka, garantindo a estabilidade durante as indisponibilidades.

Os dados s√£o empacotados em registros ou mensagens contendo um cabe√ßalho, uma chave opcional e o valor do dado propriamente dito. S√£o enviados em lotes com um ou mais registros, com seu pr√≥prio cabe√ßalho, em um processo chamado _flush_.

O produtor pode solicitar tr√™s tipos de confirma√ß√£o de recebimento ap√≥s envio:

- `acks=0` n√£o aguarda confirma√ß√£o. √â mais r√°pido, mas n√£o garante a entrega.
- `acks=1` aguarda confirma√ß√£o do l√≠der, com poss√≠vel perda em caso de falha.
- `acks=all` aguarda o l√≠der e todas as demais r√©plicas, portanto n√£o h√° perdas, ao custo de performance.

O Kafka decide em qual parti√ß√£o o dado ser√° gravado. A quantidade de mensagens j√° gravadas n√£o influencia na decis√£o, portanto n√£o h√° divis√£o igualit√°ria de espa√ßo ocupado ou de quantidade de dados armazenados.

O dado recebe um identificador √∫nico incremental naquela parti√ß√£o, chamado _offset_, independente das demais parti√ß√µes. Ou seja, podemos ter o _offset_ `1` na parti√ß√£o `0` e tamb√©m na parti√ß√£o `1`, por√©m com dados diferentes sem nenhuma rela√ß√£o al√©m de estarem no mesmo t√≥pico. A ordem cronol√≥gica dos dados √© garantida dentro de uma parti√ß√£o, ou seja, o dado de _offset_ `17` certamente chegou antes do dado de _offset_ `18`. Por√©m, n√£o √© poss√≠vel garantir ordena√ß√£o entre diferentes parti√ß√µes, assim o dado de _offset_ `17` em uma parti√ß√£o pode ser anterior ao o dado de _offset_ `5` em outra.

Exemplo:

Foram enviados os dados üçå, ü•ë, üçâ, üçì e üçá ao t√≥pico `frutas` que possui duas parti√ß√µes, nessa sequ√™ncia. O Kafka decidiu armazenar da seguinte forma:

- Parti√ß√£o `0` = [üçâ, üçì]
  - Offset `1` = üçâ
  - Offset `2` = üçì
- Parti√ß√£o `1` = [üçå, ü•ë, üçá]
  - Offset `1` = üçå
  - Offset `2` = ü•ë
  - Offset `3` = üçá

Perceba que garantimos que üçì chegou ao t√≥pico ap√≥s üçâ, e que üçå chegou antes de üçá, mas nada podemos falar sobre a rela√ß√£o temporal entre üçâ e ü•ë.

Qualquer outra sequ√™ncia seria v√°lida, desde que os _offsets_ na mesma parti√ß√£o garantam a sequ√™ncia interna.

#### Consumo

Consumidores l√™em dados de t√≥picos. N√£o √© necess√°rio saber qual a parti√ß√£o ou qual _broker_ acessar, mas somente o endere√ßo de um dos _brokers_ do _cluster_ e o nome do t√≥pico. Toda a resolu√ß√£o √© feita pelo Kafka, garantindo a estabilidade durante as indisponibilidades.

Os dados ser√£o lidos ordenadamente dentro de cada parti√ß√£o, por√©m as parti√ß√µes ser√£o tratadas paralelamente. Ou seja, n√£o h√° garantia de entrega na ordem em que os dados chegaram no t√≥pico, mas somente dentro de cada parti√ß√£o.

Por exemplo, considerando o t√≥pico `frutas` no estado definido acima, um consumidor pode receber [üçå, ü•ë, üçâ, üçì, üçá] conforme a sequ√™ncia enviada, por√©m seria uma coincid√™ncia. S√£o igualmente v√°lidas e poss√≠vel quaisquer combina√ß√µes em que üçâ venha antes de üçì, e que üçá venha depois de ü•ë que por sua vez venha depois de üçå.

Ilustrando casos v√°lidos:

- [üçâ, üçì, üçå, ü•ë, üçá], em que se consumiu a parti√ß√£o `0` e depois a `1`;
- [üçå, ü•ë, üçá, üçâ, üçì], em que se consumiu a parti√ß√£o `1` e depois a `0`;
- [üçå, ü•ë, üçâ, üçì, üçá], em que se consumiu alternadamente, mantendo a sequencia original por coincid√™ncia;
- [üçå, ü•ë, üçâ, üçá, üçì], em que se consumiu alternadamente, n√£o mantendo a sequencia original mas mantendo a sequ√™ncia entre parti√ß√µes;
- [üçâ, üçå, ü•ë, üçì, üçá], como acima, mas em outra combina√ß√£o.

Os _offsets_ atuais de cada consumidor indicam o ponto atual de leitura de um consumidor em um t√≥pico, por parti√ß√£o, e permitem continuar do mesmo ponto ao retomar o consumo. Ficam armazenados no t√≥pico `__consumer_offsets` e s√£o mantidos automaticamente. Na entrega o consumidor ter√° o seu registro de _offsets_ atual alterado pelo Kafka, de forma que ele n√£o o receber√° em duplicidade, de acordo com a sem√¢ntica de entrega estabelecida.

O consumidor pode selecionar uma entre tr√™s sem√¢nticas de entrega:

- `at most once`, onde o _offset_ √© ajustado ao realizar a leitura, e em caso de erro na transmiss√£o a mensagem n√£o ser√° mais lida;
- `at least once`: onde o _offset_ √© ajustado somente ao final do processo, e em caso de erro na altera√ß√£o do _offset_ a mensagem ser√° enviada novamente. √â o m√©todo preferido, por√©m deve-se garantir a idempot√™ncia no lado do consumidor;
- `exactly once`: onde √© garantida a entrega uma e somente uma vez, por√©m √© restrita a processos internos do Kafka .

#### Chaves em mensagens

Em alguns casos de uso podemos necessitar de algum controle sobre o ordenamento das mensagens. Para isso, podemos enviar junto aos dados uma chave. O Kafka garante que dados enviados com a mesma chave ser√£o gravados na mesma parti√ß√£o, desde que o n√∫mero de parti√ß√µes se mantenha inalterado. Dessa maneira, temos a garantia do sequenciamento para mensagens com chaves semelhantes, j√° que estar√£o na mesma parti√ß√£o. Voc√™ ainda n√£o poder√° escolher em qual parti√ß√£o a primeira mensagem daquela chave ir√° ficar.

Um caso de uso comum seria o recebimento de posi√ß√µes GPS de diversos ve√≠culos onde queremos garantir as leituras na sequ√™ncia para cada um deles. Poder√≠amos obter essa garantia enviado o identificador do ve√≠culo na chave, por exemplo. Isso for√ßaria as leituras a ficarem na mesma parti√ß√£o, onde a ordem √© garantida.

As chaves, assim como os dados, s√£o armazenados e transportados em forma bin√°ria em _arrays_ de _bytes_, e podem ser serializados e desserializados pelos clientes conforme a necessidade.

#### Grupos de consumidores

Para conseguirmos paralelizar o consumo sem repetir a leitura de um dado entre as inst√¢ncias consumidoras, precisamos criar uma afinidade entre elas. Fazemos isso criando grupos de consumidores, que nada mais s√£o do que indicadores de que eles compartilham o mesmo _offset_ em cada parti√ß√£o.

Um grupo de consumidores √© definido por um nome, e representa geralmente um _cluster_ de consumidores de uma √∫nica aplica√ß√£o.

Em um grupo, uma parti√ß√£o sempre ser√° lida pelo mesmo consumidor, garantindo a ordena√ß√£o. Essa coordena√ß√£o √© feita automaticamente pelo Kafka.

Caso hajam mais consumidores do que parti√ß√µes, eles ficar√£o inativos. Ainda assim podem ser √∫teis, pois ser√£o acionados assim que um dos consumidores fique indispon√≠vel.
 